#!/usr/bin/env python3
"""
Service de transcription Vosk en temps r√©el mot par mot
- Streaming audio en continu
- Reconnaissance mot par mot en temps r√©el
- Consolidation de phrase √† la fin
- Support des speakers (client/agent)
"""

import os
import time
import json
import threading
import queue
import wave
import tempfile
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import soundfile as sf
import redis
import vosk
import subprocess
import shutil

# Configuration
MONITOR_DIR = os.getenv("MONITOR_DIR", "/home/nfs_proxip_monitor")
REDIS_URL = os.getenv("REDIS_URL", "redis://127.0.0.1:6379/0")
CHANNEL = os.getenv("TRANSCRIPT_CHANNEL", "transcripts.realtime.v2")
VOSK_MODEL_PATH = os.getenv("VOSK_MODEL_PATH", "/opt/vosk/vosk-model")
LANGUAGE = os.getenv("LANGUAGE", "fr")

SAMPLE_RATE = 8000  # SLN 16-bit mono 8kHz
BYTES_PER_SAMPLE = 2
CHUNK_SECONDS = 2  # Chunks plus petits pour le temps r√©el
CHUNK_BYTES = SAMPLE_RATE * BYTES_PER_SAMPLE * CHUNK_SECONDS
SCAN_INTERVAL = 0.2  # Scan tr√®s fr√©quent pour le temps r√©el

# Configuration Vosk
VOSK_CONFIG = {
    'sample_rate': SAMPLE_RATE,
    'max_alternatives': 1,
    'partial_results': True,  # R√©sultats partiels pour le temps r√©el
    'word_timings': True,     # Timestamps des mots
    'max_alternatives': 1
}

class VoskRealtimeTranscriber:
    """Transcriber Vosk en temps r√©el avec streaming mot par mot"""
    
    def __init__(self):
        self.redis_client = redis.from_url(REDIS_URL)
        self.model = None
        self.rec = None
        self.active_calls: Dict[str, Dict] = {}
        self.audio_buffers: Dict[str, List[bytes]] = {}
        self.transcript_buffers: Dict[str, List[str]] = {}
        self.last_partial: Dict[str, str] = {}
        self.speaker_detection: Dict[str, str] = {}
        
        # Initialiser le mod√®le Vosk
        self._init_vosk_model()
        
    def _init_vosk_model(self):
        """Initialise le mod√®le Vosk"""
        try:
            if not os.path.exists(VOSK_MODEL_PATH):
                print(f"‚ùå Mod√®le Vosk non trouv√©: {VOSK_MODEL_PATH}")
                print("üí° T√©l√©chargez le mod√®le avec: wget https://alphacephei.com/vosk/models/vosk-model-small-fr-0.22.zip")
                return False
                
            print(f"üîß Chargement du mod√®le Vosk: {VOSK_MODEL_PATH}")
            self.model = vosk.Model(VOSK_MODEL_PATH)
            self.rec = vosk.KaldiRecognizer(self.model, SAMPLE_RATE)
            self.rec.SetWords(True)  # Activer les timestamps des mots
            print("‚úÖ Mod√®le Vosk charg√© avec succ√®s")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur chargement mod√®le Vosk: {e}")
            return False
    
    def start_call_monitoring(self, call_id: str, speaker: str = "mixed"):
        """D√©marre le monitoring d'un appel"""
        if call_id not in self.active_calls:
            self.active_calls[call_id] = {
                'speaker': speaker,
                'start_time': time.time(),
                'last_audio': time.time(),
                'status': 'active'
            }
            self.audio_buffers[call_id] = []
            self.transcript_buffers[call_id] = []
            self.last_partial[call_id] = ""
            print(f"üéØ D√©marrage monitoring appel: {call_id} (speaker: {speaker})")
    
    def stop_call_monitoring(self, call_id: str):
        """Arr√™te le monitoring d'un appel et consolide la transcription"""
        if call_id in self.active_calls:
            # Consolidation finale de la phrase
            self._consolidate_final_transcript(call_id)
            
            # Nettoyage
            del self.active_calls[call_id]
            del self.audio_buffers[call_id]
            del self.transcript_buffers[call_id]
            del self.last_partial[call_id]
            print(f"üõë Arr√™t monitoring appel: {call_id}")
    
    def process_audio_chunk(self, call_id: str, audio_data: bytes, offset_bytes: int):
        """Traite un chunk audio en temps r√©el"""
        if call_id not in self.active_calls:
            return
            
        try:
            # Ajouter √† la buffer audio
            self.audio_buffers[call_id].append(audio_data)
            self.active_calls[call_id]['last_audio'] = time.time()
            
            # Traitement Vosk en temps r√©el
            if self.rec and audio_data:
                # Traitement du chunk audio
                if self.rec.AcceptWaveform(audio_data):
                    # R√©sultat final (phrase compl√®te)
                    result = json.loads(self.rec.Result())
                    if result.get('text', '').strip():
                        self._process_final_result(call_id, result, offset_bytes)
                else:
                    # R√©sultat partiel (mot par mot)
                    partial = self.rec.PartialResult()
                    partial_data = json.loads(partial)
                    if partial_data.get('partial', '').strip():
                        self._process_partial_result(call_id, partial_data, offset_bytes)
                        
        except Exception as e:
            print(f"‚ùå Erreur traitement audio chunk: {e}")
    
    def _process_partial_result(self, call_id: str, partial_data: dict, offset_bytes: int):
        """Traite un r√©sultat partiel (mot par mot)"""
        partial_text = partial_data.get('partial', '').strip()
        
        if partial_text and partial_text != self.last_partial.get(call_id, ""):
            self.last_partial[call_id] = partial_text
            
            # Envoyer le mot en temps r√©el
            payload = {
                "callId": call_id,
                "tsMs": int(time.time() * 1000),
                "speaker": self.active_calls[call_id]['speaker'],
                "lang": LANGUAGE,
                "confidence": 0.8,  # Vosk ne donne pas de confidence
                "offsetBytes": offset_bytes,
                "status": "partial",
                "text": partial_text,
                "processingTimeMs": 0,  # Temps r√©el = 0
                "engine": "vosk",
                "realtime": True
            }
            
            # Publier sur Redis
            self.redis_client.publish(CHANNEL, json.dumps(payload))
            print(f"üî§ [REALTIME] {call_id} - {partial_text}")
    
    def _process_final_result(self, call_id: str, result: dict, offset_bytes: int):
        """Traite un r√©sultat final (phrase compl√®te)"""
        final_text = result.get('text', '').strip()
        
        if final_text:
            # Ajouter au buffer de transcription
            self.transcript_buffers[call_id].append(final_text)
            
            # Envoyer la phrase finale consolid√©e
            payload = {
                "callId": call_id,
                "tsMs": int(time.time() * 1000),
                "speaker": self.active_calls[call_id]['speaker'],
                "lang": LANGUAGE,
                "confidence": 0.9,  # Plus √©lev√© pour les phrases finales
                "offsetBytes": offset_bytes,
                "status": "completed",
                "text": final_text,
                "processingTimeMs": 0,  # Temps r√©el = 0
                "engine": "vosk",
                "realtime": False
            }
            
            # Publier sur Redis
            self.redis_client.publish(CHANNEL, json.dumps(payload))
            print(f"üìù [FINAL] {call_id} - {final_text}")
    
    def _consolidate_final_transcript(self, call_id: str):
        """Consolide la transcription finale d'un appel"""
        if call_id in self.transcript_buffers and self.transcript_buffers[call_id]:
            # Joindre tous les segments en une phrase finale
            final_text = " ".join(self.transcript_buffers[call_id])
            
            payload = {
                "callId": call_id,
                "tsMs": int(time.time() * 1000),
                "speaker": self.active_calls[call_id]['speaker'],
                "lang": LANGUAGE,
                "confidence": 0.95,  # Tr√®s √©lev√© pour la consolidation
                "offsetBytes": 0,
                "status": "consolidated",
                "text": final_text,
                "processingTimeMs": 0,
                "engine": "vosk",
                "realtime": False,
                "consolidated": True
            }
            
            # Publier la version consolid√©e
            self.redis_client.publish(CHANNEL, json.dumps(payload))
            print(f"üîó [CONSOLIDATED] {call_id} - {final_text}")
    
    def monitor_directory(self):
        """Monitore le r√©pertoire pour les nouveaux fichiers audio"""
        print(f"üîç D√©marrage monitoring r√©pertoire: {MONITOR_DIR}")
        
        while True:
            try:
                # Scanner les appels actifs
                active_calls = self._scan_active_calls()
                
                # Traiter chaque appel
                for call_id, files in active_calls.items():
                    if call_id not in self.active_calls:
                        # Nouvel appel
                        self.start_call_monitoring(call_id)
                    
                    # Traiter les fichiers audio
                    for audio_file in files:
                        self._process_audio_file(call_id, audio_file)
                
                # Nettoyer les appels inactifs
                self._cleanup_inactive_calls()
                
                time.sleep(SCAN_INTERVAL)
                
            except KeyboardInterrupt:
                print("üõë Arr√™t du monitoring")
                break
            except Exception as e:
                print(f"‚ùå Erreur monitoring: {e}")
                time.sleep(1)
    
    def _scan_active_calls(self) -> Dict[str, List[Path]]:
        """Scanne les appels actifs dans le r√©pertoire"""
        calls = {}
        current_time = time.time()
        
        try:
            monitor_path = Path(MONITOR_DIR)
            if not monitor_path.exists():
                return calls
            
            for f in monitor_path.iterdir():
                if not f.is_file() or f.suffix not in (".sln", ".wav"):
                    continue
                
                # V√©rifier si le fichier a √©t√© modifi√© r√©cemment
                try:
                    mtime = f.stat().st_mtime
                    if current_time - mtime > 30:  # 30 secondes
                        continue
                except:
                    continue
                
                # Parser le nom de fichier
                name = f.name
                parts = name.split("-")
                if len(parts) < 2:
                    continue
                    
                ts_phone = parts[0] + "-" + parts[1]
                call_id = ts_phone
                
                # D√©tecter le speaker bas√© sur le nom de fichier
                speaker = "mixed"
                if "in" in name.lower():
                    speaker = "client"
                elif "out" in name.lower():
                    speaker = "agent"
                
                if call_id not in calls:
                    calls[call_id] = []
                calls[call_id].append((f, speaker))
                
        except Exception as e:
            print(f"‚ùå Erreur scan r√©pertoire: {e}")
        
        return calls
    
    def _process_audio_file(self, call_id: str, file_info: Tuple[Path, str]):
        """Traite un fichier audio pour un appel"""
        audio_file, speaker = file_info
        
        try:
            # Mettre √† jour le speaker si n√©cessaire
            if call_id in self.active_calls:
                self.active_calls[call_id]['speaker'] = speaker
            
            # Lire le fichier audio
            if audio_file.suffix == ".sln":
                with open(audio_file, 'rb') as f:
                    audio_data = f.read()
            elif audio_file.suffix == ".wav":
                with wave.open(str(audio_file), 'rb') as wav:
                    audio_data = wav.readframes(wav.getnframes())
            
            # Traiter par chunks pour le temps r√©el
            offset = 0
            while offset < len(audio_data):
                chunk = audio_data[offset:offset + CHUNK_BYTES]
                if chunk:
                    self.process_audio_chunk(call_id, chunk, offset)
                offset += CHUNK_BYTES
                
        except Exception as e:
            print(f"‚ùå Erreur traitement fichier {audio_file}: {e}")
    
    def _cleanup_inactive_calls(self):
        """Nettoie les appels inactifs"""
        current_time = time.time()
        inactive_calls = []
        
        for call_id, call_info in self.active_calls.items():
            if current_time - call_info['last_audio'] > 60:  # 1 minute d'inactivit√©
                inactive_calls.append(call_id)
        
        for call_id in inactive_calls:
            self.stop_call_monitoring(call_id)

def main():
    """Fonction principale"""
    print("üöÄ D√©marrage du service Vosk en temps r√©el")
    print(f"üìÅ R√©pertoire monitor√©: {MONITOR_DIR}")
    print(f"üîó Redis: {REDIS_URL}")
    print(f"üì° Canal: {CHANNEL}")
    print(f"üéØ Mod√®le Vosk: {VOSK_MODEL_PATH}")
    
    # Cr√©er le transcriber
    transcriber = VoskRealtimeTranscriber()
    
    if not transcriber.model:
        print("‚ùå Impossible de d√©marrer sans mod√®le Vosk")
        return
    
    # D√©marrer le monitoring
    try:
        transcriber.monitor_directory()
    except KeyboardInterrupt:
        print("üõë Arr√™t demand√© par l'utilisateur")
    finally:
        print("üßπ Nettoyage...")

if __name__ == "__main__":
    main()
