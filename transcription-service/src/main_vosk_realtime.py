#!/usr/bin/env python3
"""
Service de transcription Vosk en temps rÃ©el mot par mot
- Streaming audio en continu
- Reconnaissance mot par mot en temps rÃ©el
- Consolidation de phrase Ã  la fin
- Support des speakers (client/agent)
"""

import os
import time
import json
import threading
import queue
import wave
import tempfile
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import soundfile as sf
import redis
import vosk
import subprocess
import shutil

# Configuration
MONITOR_DIR = os.getenv("MONITOR_DIR", "/home/nfs_proxip_monitor")
REDIS_URL = os.getenv("REDIS_URL", "redis://127.0.0.1:6379/0")
CHANNEL = os.getenv("TRANSCRIPT_CHANNEL", "transcripts.realtime.v2")
VOSK_MODEL_PATH = os.getenv("VOSK_MODEL_PATH", "/opt/vosk/vosk-model")
LANGUAGE = os.getenv("LANGUAGE", "fr")

SAMPLE_RATE = 8000  # SLN 16-bit mono 8kHz
BYTES_PER_SAMPLE = 2
CHUNK_SECONDS = 2  # Chunks plus petits pour le temps rÃ©el
CHUNK_BYTES = SAMPLE_RATE * BYTES_PER_SAMPLE * CHUNK_SECONDS
SCAN_INTERVAL = 0.2  # Scan trÃ¨s frÃ©quent pour le temps rÃ©el

# Configuration Vosk
VOSK_CONFIG = {
    'sample_rate': SAMPLE_RATE,
    'max_alternatives': 1,
    'partial_results': True,  # RÃ©sultats partiels pour le temps rÃ©el
    'word_timings': True,     # Timestamps des mots
    'max_alternatives': 1
}

class VoskRealtimeTranscriber:
    """Transcriber Vosk en temps rÃ©el avec streaming mot par mot"""
    
    def __init__(self):
        self.redis_client = redis.from_url(REDIS_URL)
        self.model = None
        self.rec = None
        self.active_calls: Dict[str, Dict] = {}
        self.audio_buffers: Dict[str, List[bytes]] = {}
        self.transcript_buffers: Dict[str, List[str]] = {}
        self.last_partial: Dict[str, str] = {}
        self.speaker_detection: Dict[str, str] = {}
        
        # Initialiser le modÃ¨le Vosk
        self._init_vosk_model()
        
    def _init_vosk_model(self):
        """Initialise le modÃ¨le Vosk"""
        try:
            if not os.path.exists(VOSK_MODEL_PATH):
                print(f"âŒ ModÃ¨le Vosk non trouvÃ©: {VOSK_MODEL_PATH}")
                print("ğŸ’¡ TÃ©lÃ©chargez le modÃ¨le avec: wget https://alphacephei.com/vosk/models/vosk-model-small-fr-0.22.zip")
                return False
                
            print(f"ğŸ”§ Chargement du modÃ¨le Vosk: {VOSK_MODEL_PATH}")
            self.model = vosk.Model(VOSK_MODEL_PATH)
            self.rec = vosk.KaldiRecognizer(self.model, SAMPLE_RATE)
            self.rec.SetWords(True)  # Activer les timestamps des mots
            print("âœ… ModÃ¨le Vosk chargÃ© avec succÃ¨s")
            return True
            
        except Exception as e:
            print(f"âŒ Erreur chargement modÃ¨le Vosk: {e}")
            return False
    
    def start_call_monitoring(self, call_id: str, speaker: str = "mixed"):
        """DÃ©marre le monitoring d'un appel"""
        if call_id not in self.active_calls:
            self.active_calls[call_id] = {
                'speaker': speaker,
                'start_time': time.time(),
                'last_audio': time.time(),
                'status': 'active'
            }
            self.audio_buffers[call_id] = []
            self.transcript_buffers[call_id] = []
            self.last_partial[call_id] = ""
            print(f"ğŸ¯ DÃ©marrage monitoring appel: {call_id} (speaker: {speaker})")
    
    def stop_call_monitoring(self, call_id: str):
        """ArrÃªte le monitoring d'un appel et consolide la transcription"""
        if call_id in self.active_calls:
            # Consolidation finale de la phrase
            self._consolidate_final_transcript(call_id)
            
            # Nettoyage
            del self.active_calls[call_id]
            del self.audio_buffers[call_id]
            del self.transcript_buffers[call_id]
            del self.last_partial[call_id]
            print(f"ğŸ›‘ ArrÃªt monitoring appel: {call_id}")
    
    def process_audio_chunk(self, call_id: str, audio_data: bytes, offset_bytes: int):
        """Traite un chunk audio en temps rÃ©el"""
        if call_id not in self.active_calls:
            return
            
        try:
            # Ajouter Ã  la buffer audio
            self.audio_buffers[call_id].append(audio_data)
            self.active_calls[call_id]['last_audio'] = time.time()
            
            # Traitement Vosk en temps rÃ©el
            if self.rec and audio_data:
                # Traitement du chunk audio
                if self.rec.AcceptWaveform(audio_data):
                    # RÃ©sultat final (phrase complÃ¨te)
                    result = json.loads(self.rec.Result())
                    if result.get('text', '').strip():
                        self._process_final_result(call_id, result, offset_bytes)
                else:
                    # RÃ©sultat partiel (mot par mot)
                    partial = self.rec.PartialResult()
                    partial_data = json.loads(partial)
                    if partial_data.get('partial', '').strip():
                        self._process_partial_result(call_id, partial_data, offset_bytes)
                        
        except Exception as e:
            print(f"âŒ Erreur traitement audio chunk: {e}")
    
    def _process_partial_result(self, call_id: str, partial_data: dict, offset_bytes: int):
        """Traite un rÃ©sultat partiel (mot par mot)"""
        partial_text = partial_data.get('partial', '').strip()
        
        if partial_text and partial_text != self.last_partial.get(call_id, ""):
            self.last_partial[call_id] = partial_text
            
            # Envoyer le mot en temps rÃ©el
            payload = {
                "callId": call_id,
                "tsMs": int(time.time() * 1000),
                "speaker": self.active_calls[call_id]['speaker'],
                "lang": LANGUAGE,
                "confidence": 0.8,  # Vosk ne donne pas de confidence
                "offsetBytes": offset_bytes,
                "status": "partial",
                "text": partial_text,
                "processingTimeMs": 0,  # Temps rÃ©el = 0
                "engine": "vosk",
                "realtime": True
            }
            
            # Publier sur Redis
            self.redis_client.publish(CHANNEL, json.dumps(payload))
            print(f"ğŸ”¤ [REALTIME] {call_id} - {partial_text}")
    
    def _process_final_result(self, call_id: str, result: dict, offset_bytes: int):
        """Traite un rÃ©sultat final (phrase complÃ¨te)"""
        final_text = result.get('text', '').strip()
        
        if final_text:
            # Ajouter au buffer de transcription
            self.transcript_buffers[call_id].append(final_text)
            
            # Envoyer la phrase finale consolidÃ©e
            payload = {
                "callId": call_id,
                "tsMs": int(time.time() * 1000),
                "speaker": self.active_calls[call_id]['speaker'],
                "lang": LANGUAGE,
                "confidence": 0.9,  # Plus Ã©levÃ© pour les phrases finales
                "offsetBytes": offset_bytes,
                "status": "completed",
                "text": final_text,
                "processingTimeMs": 0,  # Temps rÃ©el = 0
                "engine": "vosk",
                "realtime": False
            }
            
            # Publier sur Redis
            self.redis_client.publish(CHANNEL, json.dumps(payload))
            print(f"ğŸ“ [FINAL] {call_id} - {final_text}")
    
    def _consolidate_final_transcript(self, call_id: str):
        """Consolide la transcription finale d'un appel"""
        if call_id in self.transcript_buffers and self.transcript_buffers[call_id]:
            # Joindre tous les segments en une phrase finale
            final_text = " ".join(self.transcript_buffers[call_id])
            
            payload = {
                "callId": call_id,
                "tsMs": int(time.time() * 1000),
                "speaker": self.active_calls[call_id]['speaker'],
                "lang": LANGUAGE,
                "confidence": 0.95,  # TrÃ¨s Ã©levÃ© pour la consolidation
                "offsetBytes": 0,
                "status": "consolidated",
                "text": final_text,
                "processingTimeMs": 0,
                "engine": "vosk",
                "realtime": False,
                "consolidated": True
            }
            
            # Publier la version consolidÃ©e
            self.redis_client.publish(CHANNEL, json.dumps(payload))
            print(f"ğŸ”— [CONSOLIDATED] {call_id} - {final_text}")
    
    def monitor_directory(self):
        """Monitore le rÃ©pertoire pour les nouveaux fichiers audio"""
        print(f"ğŸ” DÃ©marrage monitoring rÃ©pertoire: {MONITOR_DIR}")
        
        while True:
            try:
                # Scanner les appels actifs
                active_calls = self._scan_active_calls()
                
                # Traiter chaque appel
                for call_id, files in active_calls.items():
                    if call_id not in self.active_calls:
                        # Nouvel appel
                        self.start_call_monitoring(call_id)
                    
                    # Traiter les fichiers audio
                    for audio_file in files:
                        self._process_audio_file(call_id, audio_file)
                
                # Nettoyer les appels inactifs
                self._cleanup_inactive_calls()
                
                time.sleep(SCAN_INTERVAL)
                
            except KeyboardInterrupt:
                print("ğŸ›‘ ArrÃªt du monitoring")
                break
            except Exception as e:
                print(f"âŒ Erreur monitoring: {e}")
                time.sleep(1)
    
    def _scan_active_calls(self) -> Dict[str, List[Path]]:
        """Scanne les appels actifs dans le rÃ©pertoire"""
        calls = {}
        current_time = time.time()
        
        try:
            monitor_path = Path(MONITOR_DIR)
            if not monitor_path.exists():
                return calls
            
            for f in monitor_path.iterdir():
                if not f.is_file() or f.suffix not in (".sln", ".wav"):
                    continue
                
                # VÃ©rifier si le fichier a Ã©tÃ© modifiÃ© rÃ©cemment
                try:
                    mtime = f.stat().st_mtime
                    if current_time - mtime > 30:  # 30 secondes
                        continue
                except:
                    continue
                
                # Parser le nom de fichier
                name = f.name
                parts = name.split("-")
                if len(parts) < 2:
                    continue
                    
                ts_phone = parts[0] + "-" + parts[1]
                call_id = ts_phone
                
                # DÃ©tecter le speaker basÃ© sur le nom de fichier
                speaker = "mixed"
                if "in" in name.lower():
                    speaker = "client"
                elif "out" in name.lower():
                    speaker = "agent"
                
                if call_id not in calls:
                    calls[call_id] = []
                calls[call_id].append((f, speaker))
                
        except Exception as e:
            print(f"âŒ Erreur scan rÃ©pertoire: {e}")
        
        return calls
    
    def _process_audio_file(self, call_id: str, file_info: Tuple[Path, str]):
        """Traite un fichier audio pour un appel"""
        audio_file, speaker = file_info
        
        try:
            # Mettre Ã  jour le speaker si nÃ©cessaire
            if call_id in self.active_calls:
                self.active_calls[call_id]['speaker'] = speaker
            
            # Lire le fichier audio
            if audio_file.suffix == ".sln":
                with open(audio_file, 'rb') as f:
                    audio_data = f.read()
            elif audio_file.suffix == ".wav":
                with wave.open(str(audio_file), 'rb') as wav:
                    audio_data = wav.readframes(wav.getnframes())
            
            # Traiter par chunks pour le temps rÃ©el
            offset = 0
            while offset < len(audio_data):
                chunk = audio_data[offset:offset + CHUNK_BYTES]
                if chunk:
                    self.process_audio_chunk(call_id, chunk, offset)
                offset += CHUNK_BYTES
                
        except Exception as e:
            print(f"âŒ Erreur traitement fichier {audio_file}: {e}")
    
    def _cleanup_inactive_calls(self):
        """Nettoie les appels inactifs"""
        current_time = time.time()
        inactive_calls = []
        
        for call_id, call_info in self.active_calls.items():
            if current_time - call_info['last_audio'] > 60:  # 1 minute d'inactivitÃ©
                inactive_calls.append(call_id)
        
        for call_id in inactive_calls:
            self.stop_call_monitoring(call_id)

def main():
    """Fonction principale"""
    print("ğŸš€ DÃ©marrage du service Vosk en temps rÃ©el")
    print(f"ğŸ“ RÃ©pertoire monitorÃ©: {MONITOR_DIR}")
    print(f"ğŸ”— Redis: {REDIS_URL}")
    print(f"ğŸ“¡ Canal: {CHANNEL}")
    print(f"ğŸ¯ ModÃ¨le Vosk: {VOSK_MODEL_PATH}")
    
    # CrÃ©er le transcriber
    transcriber = VoskRealtimeTranscriber()
    
    if not transcriber.model:
        print("âŒ Impossible de dÃ©marrer sans modÃ¨le Vosk")
        return
    
    # DÃ©marrer le monitoring
    try:
        transcriber.monitor_directory()
    except KeyboardInterrupt:
        print("ğŸ›‘ ArrÃªt demandÃ© par l'utilisateur")
    finally:
        print("ğŸ§¹ Nettoyage...")

if __name__ == "__main__":
    main()
